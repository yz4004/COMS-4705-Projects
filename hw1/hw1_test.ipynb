{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71a0d49e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '-f'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18936/1390961603.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrigramModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[1;31m# put test code here...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18936/1390961603.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, corpusfile)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;31m# Iterate through the corpus once to build a lexicon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mgenerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorpus_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpusfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlexicon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_lexicon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlexicon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"UNK\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlexicon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"START\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18936/1390961603.py\u001b[0m in \u001b[0;36mget_lexicon\u001b[1;34m(corpus)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_lexicon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mword_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mword_counts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18936/1390961603.py\u001b[0m in \u001b[0;36mcorpus_reader\u001b[1;34m(corpusfile, lexicon)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcorpus_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpusfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlexicon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpusfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '-f'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import os.path\n",
    "\"\"\"\n",
    "COMS W4705 - Natural Language Processing\n",
    "Homework 1 - Programming Component: Trigram Language Models\n",
    "Yassine Benajiba\n",
    "\"\"\"\n",
    "\n",
    "def corpus_reader(corpusfile, lexicon=None): \n",
    "    with open(corpusfile,'r') as corpus: \n",
    "        for line in corpus: \n",
    "            if line.strip():\n",
    "                sequence = line.lower().strip().split()\n",
    "                if lexicon: \n",
    "                    yield [word if word in lexicon else \"UNK\" for word in sequence]\n",
    "                else: \n",
    "                    yield sequence\n",
    "\n",
    "def get_lexicon(corpus):\n",
    "    word_counts = defaultdict(int)\n",
    "    for sentence in corpus:\n",
    "        for word in sentence: \n",
    "            word_counts[word] += 1\n",
    "    return set(word for word in word_counts if word_counts[word] > 1)  \n",
    "\n",
    "\n",
    "\n",
    "def get_ngrams(sequence, n):\n",
    "    \"\"\"\n",
    "    COMPLETE THIS FUNCTION (PART 1)\n",
    "    Given a sequence, this function should return a list of n-grams, where each n-gram is a Python tuple.\n",
    "    This should work for arbitrary values of 1 <= n < len(sequence).\n",
    "    \"\"\"\n",
    "\n",
    "    return []\n",
    "\n",
    "\n",
    "class TrigramModel(object):\n",
    "    \n",
    "    def __init__(self, corpusfile):\n",
    "    \n",
    "        # Iterate through the corpus once to build a lexicon \n",
    "        generator = corpus_reader(corpusfile)\n",
    "        self.lexicon = get_lexicon(generator)\n",
    "        self.lexicon.add(\"UNK\")\n",
    "        self.lexicon.add(\"START\")\n",
    "        self.lexicon.add(\"STOP\")\n",
    "    \n",
    "        # Now iterate through the corpus again and count ngrams\n",
    "        generator = corpus_reader(corpusfile, self.lexicon)\n",
    "        self.count_ngrams(generator)\n",
    "\n",
    "\n",
    "    def count_ngrams(self, corpus):\n",
    "        \"\"\"\n",
    "        COMPLETE THIS METHOD (PART 2)\n",
    "        Given a corpus iterator, populate dictionaries of unigram, bigram,\n",
    "        and trigram counts. \n",
    "        \"\"\"\n",
    "   \n",
    "        self.unigramcounts = {} # might want to use defaultdict or Counter instead\n",
    "        self.bigramcounts = {} \n",
    "        self.trigramcounts = {} \n",
    "\n",
    "        ##Your code here\n",
    "\n",
    "        return\n",
    "\n",
    "    def raw_trigram_probability(self,trigram):\n",
    "        \"\"\"\n",
    "        COMPLETE THIS METHOD (PART 3)\n",
    "        Returns the raw (unsmoothed) trigram probability\n",
    "        \"\"\"\n",
    "        return 0.0\n",
    "\n",
    "    def raw_bigram_probability(self, bigram):\n",
    "        \"\"\"\n",
    "        COMPLETE THIS METHOD (PART 3)\n",
    "        Returns the raw (unsmoothed) bigram probability\n",
    "        \"\"\"\n",
    "        return 0.0\n",
    "    \n",
    "    def raw_unigram_probability(self, unigram):\n",
    "        \"\"\"\n",
    "        COMPLETE THIS METHOD (PART 3)\n",
    "        Returns the raw (unsmoothed) unigram probability.\n",
    "        \"\"\"\n",
    "\n",
    "        #hint: recomputing the denominator every time the method is called\n",
    "        # can be slow! You might want to compute the total number of words once, \n",
    "        # store in the TrigramModel instance, and then re-use it.  \n",
    "        return 0.0\n",
    "\n",
    "    def generate_sentence(self,t=20): \n",
    "        \"\"\"\n",
    "        COMPLETE THIS METHOD (OPTIONAL)\n",
    "        Generate a random sentence from the trigram model. t specifies the\n",
    "        max length, but the sentence may be shorter if STOP is reached.\n",
    "        \"\"\"\n",
    "        return result            \n",
    "\n",
    "    def smoothed_trigram_probability(self, trigram):\n",
    "        \"\"\"\n",
    "        COMPLETE THIS METHOD (PART 4)\n",
    "        Returns the smoothed trigram probability (using linear interpolation). \n",
    "        \"\"\"\n",
    "        lambda1 = 1/3.0\n",
    "        lambda2 = 1/3.0\n",
    "        lambda3 = 1/3.0\n",
    "        return 0.0\n",
    "        \n",
    "    def sentence_logprob(self, sentence):\n",
    "        \"\"\"\n",
    "        COMPLETE THIS METHOD (PART 5)\n",
    "        Returns the log probability of an entire sequence.\n",
    "        \"\"\"\n",
    "        return float(\"-inf\")\n",
    "\n",
    "    def perplexity(self, corpus):\n",
    "        \"\"\"\n",
    "        COMPLETE THIS METHOD (PART 6) \n",
    "        Returns the log probability of an entire sequence.\n",
    "        \"\"\"\n",
    "        return float(\"inf\") \n",
    "\n",
    "\n",
    "def essay_scoring_experiment(training_file1, training_file2, testdir1, testdir2):\n",
    "\n",
    "        model1 = TrigramModel(training_file1)\n",
    "        model2 = TrigramModel(training_file2)\n",
    "\n",
    "        total = 0\n",
    "        correct = 0       \n",
    " \n",
    "        for f in os.listdir(testdir1):\n",
    "            pp = model1.perplexity(corpus_reader(os.path.join(testdir1, f), model1.lexicon))\n",
    "            # .. \n",
    "    \n",
    "        for f in os.listdir(testdir2):\n",
    "            pp = model2.perplexity(corpus_reader(os.path.join(testdir2, f), model2.lexicon))\n",
    "            # .. \n",
    "        \n",
    "        return 0.0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    model = TrigramModel(sys.argv[1]) \n",
    "\n",
    "    # put test code here...\n",
    "    # or run the script from the command line with \n",
    "    # $ python -i trigram_model.py [corpus_file]\n",
    "    # >>> \n",
    "    #\n",
    "    # you can then call methods on the model instance in the interactive \n",
    "    # Python prompt. \n",
    "\n",
    "    \n",
    "    # Testing perplexity: \n",
    "    # dev_corpus = corpus_reader(sys.argv[2], model.lexicon)\n",
    "    # pp = model.perplexity(dev_corpus)\n",
    "    # print(pp)\n",
    "\n",
    "\n",
    "    # Essay scoring experiment: \n",
    "    # acc = essay_scoring_experiment('train_high.txt', 'train_low.txt\", \"test_high\", \"test_low\")\n",
    "    # print(acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051f2cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83cf665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_ngrams(self, corpus):\n",
    "    \"\"\"\n",
    "    COMPLETE THIS METHOD (PART 2)\n",
    "    Given a corpus iterator, populate dictionaries of unigram, bigram,\n",
    "    and trigram counts. \n",
    "    \"\"\"\n",
    "\n",
    "    self.unigramcounts = {} # might want to use defaultdict or Counter instead\n",
    "    self.bigramcounts = {} \n",
    "    self.trigramcounts = {} \n",
    "\n",
    "    ##Your code here\n",
    "    unigramcounts[0] = (\"START\",)\n",
    "    while(corpus != null):\n",
    "        \n",
    "        \n",
    "        # corpus = next(corpus)\n",
    "    \n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b397b3f0",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5b200877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "[('START', 'START', 1), ('START', 1, 2), (1, 2, 3), (2, 3, 4), (3, 4, 'END')]\n"
     ]
    }
   ],
   "source": [
    "def get_ngrams(sequence, n):\n",
    "    \"\"\"\n",
    "    COMPLETE THIS FUNCTION (PART 1)\n",
    "    Given a sequence, this function should return a list of n-grams, where each n-gram is a Python tuple.\n",
    "    This should work for arbitrary values of 1 <= n < len(sequence).\n",
    "    \"\"\"\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    # sequence.insert(0, \"START\")\n",
    "    \n",
    "    if (n == 1):\n",
    "        sequence.insert(0, \"START\")\n",
    "    else:\n",
    "        for i in range(n-1):\n",
    "            sequence.insert(i, \"START\")\n",
    "    \n",
    "\n",
    "    \n",
    "    sequence.append(\"END\")\n",
    "    print(len(sequence))\n",
    "    \n",
    "    for i in range(len(sequence) - n+1): # should > len(seq)   # range 留头去尾 \n",
    "        # print(i, i+n,sequence[i:i+n], tuple(sequence[i:i+n]))\n",
    "        # result[i] = tuple(sequence[i:i+n])  # not a dict\n",
    "        result.append(tuple(sequence[i:i+n]))\n",
    "\n",
    "    return result\n",
    "\n",
    "list1 = [1,2,3,4]\n",
    "\n",
    "print(get_ngrams(list1, 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb70e943",
   "metadata": {},
   "source": [
    "list 切片\n",
    "\n",
    "生成 tuple\n",
    "\n",
    "修改一个值\n",
    "\n",
    "append 函数 在结尾插入  O(1)\n",
    "\n",
    "insert 函数 用于在中间插入 位置 值  O（1）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ceed3b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3]\n",
      "(1, 2)\n",
      "[0, 2, 3, 4]\n",
      "[0, 2, 3, 4, 5]\n",
      "[-1, 0, 2, 3, 4, 5]\n",
      "[-1, 100, 0, 2, 3, 4, 5]\n",
      "i 0\n"
     ]
    }
   ],
   "source": [
    "list1 = [1,2,3,4]\n",
    "print(list1[1:3])\n",
    "\n",
    "print(tuple(list1[0:0+2]))\n",
    "\n",
    "list1[0] = 0\n",
    "print(list1)\n",
    "\n",
    "list1.append(5)\n",
    "print(list1)\n",
    "\n",
    "list1.insert(0,-1)\n",
    "print(list1)\n",
    "\n",
    "list1.insert(1,100)\n",
    "print(list1)\n",
    "\n",
    "for i in range(1):\n",
    "    print(\"i\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d412af0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1,)\n"
     ]
    }
   ],
   "source": [
    "print(tuple(list1[0:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618f968a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff706526",
   "metadata": {},
   "source": [
    "## Part2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e0b0f70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-f'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.argv[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2bf04b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9d703099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\31557\\\\anaconda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py', '-f', 'C:\\\\Users\\\\31557\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-211ee563-d77a-460a-8330-a2772ffbe420.json']\n"
     ]
    }
   ],
   "source": [
    "print(sys.argv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec38c90f",
   "metadata": {},
   "source": [
    "dict 不会自动初始化，第一次初始化 key 需要赋值。而 default dict 可以自动识别，没有的就初始化为0。在统计 ngram 时自增 可以保持操作的一致性，代码简洁。\n",
    "\n",
    "如果只能用 dict 完成第一次初始化，可以用 try catch 第一次捕捉没有 key 的error 然后初始化为 1， 后续再 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9db2c2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'w1': 1}\n"
     ]
    }
   ],
   "source": [
    "dict1 = {}\n",
    "dict1[\"w1\"] = 1\n",
    "\n",
    "print(dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c0de4b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'w1': 2}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'w2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_41976/2931865957.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdict1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"w2\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'w2'"
     ]
    }
   ],
   "source": [
    "dict1[\"w1\"] += 1\n",
    "print(dict1)\n",
    "\n",
    "dict1[\"w2\"] += 1\n",
    "print(dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "879ea073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'w1': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "dict2 = defaultdict(int)\n",
    "\n",
    "dict2[\"w1\"] += 1\n",
    "\n",
    "print(dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9e9e4dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple1 = (1,2,3)\n",
    "tuple1[0:2]\n",
    "# tuple indices must be integers or slices,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea944516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1', 1), ('2', 2)]\n"
     ]
    }
   ],
   "source": [
    "list2 = [('1',1), ('2',2) ]\n",
    "print(list2)\n",
    "list2[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c95c5d6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18936/3737507556.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlist2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlist2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "list2 = [['1',1], ['2',2] ]\n",
    "list2[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9daa933b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1' '1']\n",
      " ['2' '2']]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "list2 = np.array([['1',1], ['2',2] ])\n",
    "# list2[:,0]\n",
    "print(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72e0da29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 0.1, '2': 0.7, '3': 0.2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(dict_values([0.1, 0.7, 0.2]), [0.1, 0.7, 0.2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict2 = {'1':0.1, \"2\":0.7, \"3\":0.2}\n",
    "print(dict2)\n",
    "\n",
    "dict2.values(), list(dict2.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f321e20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw = np.random.multinomial(1, list(dict2.values()), 1).flatten()\n",
    "draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "017a0597",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18936/2141990620.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdict2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "dict2[draw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e6c1822",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict_keys' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18936/3956067379.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdict2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'dict_keys' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "dict2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a8ea565c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1\n",
      "1 0.7\n",
      "2 0.2\n",
      "[[0, 0.1], [1, 0.7], [2, 0.2]]\n"
     ]
    }
   ],
   "source": [
    "for x, y in enumerate(dict2.values()):\n",
    "    print(x,y)\n",
    "    \n",
    "    \n",
    "# list3 = [ [x,y] for x, y in enumerate(dict2.values()) if y>=0.2  ]\n",
    "list3 = [ [x,y] for x, y in enumerate(dict2.values()) ]\n",
    "print(list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a09fe175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.7, 0.2])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list3)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "26313cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw = np.random.multinomial(1, np.array(list3)[:,1], 1).flatten()\n",
    "draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f21eaf04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(np.where(draw == 0)[0])\n",
    "print(np.where(draw == 1)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a83252de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dict2.keys())[np.where(draw == 1)[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5bd828c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "1 2\n",
      "2 3\n"
     ]
    }
   ],
   "source": [
    "for i, j in enumerate(dict2):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e97353",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
